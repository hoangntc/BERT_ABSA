{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea9b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_534066/4008460794.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJ_PATH=/home/hoang/github/BERT_ABSA\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re, datetime, random, gzip, json\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from itertools import accumulate\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "\n",
    "from time import time\n",
    "from math import ceil\n",
    "from multiprocessing import Pool\n",
    "from sentence_transformers import SentenceTransformer, models, losses, InputExample\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "\n",
    "from torch_geometric.nn import Sequential, HeteroConv, GINConv, GCNConv, SAGEConv, GATConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "PROJ_PATH = Path(os.path.join(re.sub(\"/BERT_ABSA.*$\", '', os.getcwd()), 'BERT_ABSA'))\n",
    "print(f'PROJ_PATH={PROJ_PATH}')\n",
    "sys.path.insert(1, str(PROJ_PATH))\n",
    "sys.path.insert(1, str(PROJ_PATH/'src'))\n",
    "import utils\n",
    "from utils import *\n",
    "from attention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21cf9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob.glob('../model/restaurants/*.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80d8522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJ_PATH=/home/hoang/github/BERT_ABSA\n",
      "PROJ_PATH=/home/hoang/github/BERT_ABSA\n",
      "PROJ_PATH=/home/hoang/github/BERT_ABSA\n"
     ]
    }
   ],
   "source": [
    "from dataset import DataModule\n",
    "from model import SentimentClassifier, SynSentimentClassifier, SynSemSentimentClassifier\n",
    "from main import load_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959022cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceAgent:\n",
    "    def __init__(self,\n",
    "                 proj_path,\n",
    "                 model_name='syn',\n",
    "                 ckpt_filename='epoch=4-val_loss=0.6445-val_acc=0.8003-val_macro_f1=0.7335-val_micro_f1=0.8003.ckpt',\n",
    "                 ckpt_dirname='model/laptops',\n",
    "                 hparams_filename='../src/config/laptop_config.json',\n",
    "                 device='cpu'):\n",
    "        \n",
    "        hparams = read_json(hparams_filename)\n",
    "        \n",
    "        self.proj_path = Path(proj_path)\n",
    "        assert self.proj_path.is_dir(), 'proj_path must be an existing directory'\n",
    "\n",
    "        self.checkpoint_path = self.proj_path / ckpt_dirname / ckpt_filename\n",
    "        \n",
    "        assert self.checkpoint_path.is_file(), 'checkpoint_path must be an existing file'\n",
    "        print(f'Load model: {self.checkpoint_path}')\n",
    "        \n",
    "        # data\n",
    "        self.data = DataModule(hparams['data_params'])\n",
    "        self.polarity_dict = {'positive': 0, 'negative': 1, 'neutral': 2}\n",
    "        self.transformation = hparams['data_params']['transformation']\n",
    "        self.max_length = hparams['data_params']['max_length']\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(hparams['data_params']['bert_name'])\n",
    "        \n",
    "        # model\n",
    "        if torch.cuda.is_available() and device != 'cpu':\n",
    "            map_location = lambda storage, loc: storage.cuda()\n",
    "        else:\n",
    "            map_location = 'cpu'\n",
    "            \n",
    "#         self.model = SentimentClassifier.load_from_checkpoint(\n",
    "#             checkpoint_path=str(self.checkpoint_path), map_location=map_location)\n",
    "        self.model_name = model_name\n",
    "        self.model = load_model_test(\n",
    "            self.model_name, checkpoint_path=str(self.checkpoint_path), map_location=map_location)\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def transform(self, sample):\n",
    "        seq1 = sample['text'].lower()\n",
    "        term = sample['term'].lower()\n",
    "        \n",
    "        if self.transformation == 'QA_M':\n",
    "            seq2 = f'what is the polarity of {term} ?'\n",
    "        elif self.transformation == 'MLI_M':\n",
    "            seq2 = term.lower()\n",
    "        elif self.transformation == 'KW_M':\n",
    "            seq2 = term\n",
    "            \n",
    "        if 'label' in sample:\n",
    "            label = self.polarity_dict[sample['label']]\n",
    "        else:\n",
    "            label = 0\n",
    "        return seq1, seq2, label\n",
    "        \n",
    "    def encode_text(self, seq1, seq2):\n",
    "        # encode\n",
    "        encoded_text = self.bert_tokenizer.encode_plus(\n",
    "            seq1,\n",
    "            seq2,\n",
    "            add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "            max_length=self.max_length,  # maximum length of a sentence\n",
    "            padding='max_length',  # Add [PAD]s\n",
    "            truncation=True, # Truncate up to maximum length\n",
    "            return_attention_mask=True,  # Generate the attention mask\n",
    "            return_tensors='pt',  # Ask the function to return PyTorch tensors\n",
    "        )\n",
    "        return encoded_text\n",
    "    \n",
    "#     def infer_single_instance(self, sample):\n",
    "#         '''\n",
    "#         Sample format: {'text': 'Food is good', 'term': 'food', 'label': 'positive'}\n",
    "#         '''\n",
    "#         seq1, seq2, label = self.transform(sample)\n",
    "#         encoded_text = self.encode_text(seq1, seq2)\n",
    "#         softmax = nn.Softmax(dim=1)\n",
    "#         logits = self.model(\n",
    "#             encoded_text['input_ids'],\n",
    "#             encoded_text['attention_mask'],\n",
    "#             encoded_text['token_type_ids'],\n",
    "#             torch.tensor([label]))\n",
    "#         probas = softmax(logits).squeeze().detach().numpy()\n",
    "#         return probas\n",
    "\n",
    "    def predict(self, sample):\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        input_ids = sample['input_ids']\n",
    "        attention_mask = sample['attention_mask']\n",
    "        token_type_ids = sample['token_type_ids']\n",
    "        edge_index = sample['edge_index'] if 'edge_index' in sample else None\n",
    "        label = sample['label']\n",
    "        \n",
    "        if self.model_name == 'bert':\n",
    "            prediction = softmax(self.model(\n",
    "                sample['input_ids'], \n",
    "                sample['attention_mask'],\n",
    "                sample['token_type_ids'], \n",
    "                sample['label'],\n",
    "            ))\n",
    "        elif self.model_name == 'syn' or self.model_name == 'synsem':\n",
    "            prediction = softmax(self.model(\n",
    "                sample['input_ids'], \n",
    "                sample['attention_mask'],\n",
    "                sample['token_type_ids'], \n",
    "                sample['edge_index'],\n",
    "                sample['label'],\n",
    "            ))\n",
    "        return prediction.detach().cpu().numpy().tolist()\n",
    "    def get_aux_information(self, sample, dataset='train'):\n",
    "        ids = sample['id']\n",
    "        text = sample['text']\n",
    "        label = sample['label'].detach().cpu().numpy().tolist()\n",
    "        term = sample['term']\n",
    "        tvt = len(sample['term']) * [dataset] # batch_size * ['train'/'val'/'test']\n",
    "        return ids, text, label, term, tvt\n",
    "    \n",
    "    def infer_dataset(self):\n",
    "        self.data.setup()\n",
    "        ids = []\n",
    "        text = []\n",
    "        term = []\n",
    "        label = []\n",
    "        prediction = []\n",
    "        tvt = []\n",
    "        \n",
    "        print('Inferring train ...')\n",
    "        for sample in self.data.train_dataloader():\n",
    "            # aux information\n",
    "            aux = self.get_aux_information(sample, 'train')\n",
    "            ids += aux[0]\n",
    "            text += aux[1]\n",
    "            label += aux[2]\n",
    "            term += aux[3]\n",
    "            tvt += aux[4]\n",
    "            # predict\n",
    "            prediction += self.predict(sample)\n",
    "        \n",
    "        print('Inferring validation ...')\n",
    "        for sample in self.data.mytrain_dataloader():\n",
    "            # aux information\n",
    "            aux = self.get_aux_information(sample, 'val')\n",
    "            ids += aux[0]\n",
    "            text += aux[1]\n",
    "            label += aux[2]\n",
    "            term += aux[3]\n",
    "            tvt += aux[4]\n",
    "            # predict\n",
    "            prediction += self.predict(sample)\n",
    "        \n",
    "        print('Inferring test ...')    \n",
    "        for sample in self.data.test_dataloader():\n",
    "            # aux information\n",
    "            aux = self.get_aux_information(sample, 'test')\n",
    "            ids += aux[0]\n",
    "            text += aux[1]\n",
    "            label += aux[2]\n",
    "            term += aux[3]\n",
    "            tvt += aux[4]\n",
    "            # predict\n",
    "            prediction += self.predict(sample)\n",
    "        \n",
    "        return ids, text, term, label, tvt, prediction\n",
    "    \n",
    "    def get_prediction(self):\n",
    "        out = self.infer_dataset()\n",
    "        df = pd.DataFrame({\n",
    "            'id': out[0], 'text': out[1], 'term': out[2], 'label_id': out[3], 'tvt': out[4], 'pred': out[5]})\n",
    "        df['label'] = df['label_id'].map({v:k for k,v in self.polarity_dict.items()})\n",
    "        df[['pred_0', 'pred_1', 'pred_2']] = pd.DataFrame(df.pred.tolist(), index= df.index)\n",
    "        return df[['id', 'text', 'term', 'label_id', 'label', 'tvt', 'pred_0', 'pred_1', 'pred_2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af33997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model: /home/hoang/github/BERT_ABSA/model/laptops/epoch=4-val_loss=0.6445-val_acc=0.8003-val_macro_f1=0.7335-val_micro_f1=0.8003.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "inference = InferenceAgent(proj_path=str(PROJ_PATH), model_name='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3836e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = {'text': 'Food is good', 'term': 'food', 'label': 'positive'}\n",
    "# out = inference.infer_single_instance(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def3931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring train ...\n",
      "Inferring validation ...\n",
      "Inferring test ...\n"
     ]
    }
   ],
   "source": [
    "df = inference.get_prediction()\n",
    "df.to_csv('../output/bert_laptop.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d98f13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2970</td>\n",
       "      <td>I did not have to call the support line at all.</td>\n",
       "      <td>support line</td>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "      <td>0.008857</td>\n",
       "      <td>0.946764</td>\n",
       "      <td>0.044378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2338</td>\n",
       "      <td>I take it everywhere with me because it's so e...</td>\n",
       "      <td>carry</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.997106</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2674</td>\n",
       "      <td>One drawback I noticed was sound quality via USB.</td>\n",
       "      <td>sound quality via USB</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.984814</td>\n",
       "      <td>0.004808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3011</td>\n",
       "      <td>Great OS, fabulous improvements to the existin...</td>\n",
       "      <td>OS</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.990100</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>0.002352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>I even got my teenage son one, because of the ...</td>\n",
       "      <td>Photobooth</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.990364</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.004887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  \\\n",
       "0  2970    I did not have to call the support line at all.   \n",
       "1  2338  I take it everywhere with me because it's so e...   \n",
       "2  2674  One drawback I noticed was sound quality via USB.   \n",
       "3  3011  Great OS, fabulous improvements to the existin...   \n",
       "4    76  I even got my teenage son one, because of the ...   \n",
       "\n",
       "                    term  label_id     label    tvt    pred_0    pred_1  \\\n",
       "0           support line         2   neutral  train  0.008857  0.946764   \n",
       "1                  carry         0  positive  train  0.997106  0.001536   \n",
       "2  sound quality via USB         1  negative  train  0.010378  0.984814   \n",
       "3                     OS         0  positive  train  0.990100  0.007548   \n",
       "4             Photobooth         0  positive  train  0.990364  0.004748   \n",
       "\n",
       "     pred_2  \n",
       "0  0.044378  \n",
       "1  0.001358  \n",
       "2  0.004808  \n",
       "3  0.002352  \n",
       "4  0.004887  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laptop_agent = InferenceAgent(\n",
    "#     proj_path=str(PROJ_PATH),\n",
    "#     ckpt_filename='epoch=4-val_loss=0.6445-val_acc=0.8003-val_macro_f1=0.7335-val_micro_f1=0.8003.ckpt',\n",
    "#     ckpt_dirname='model/laptops',\n",
    "#     hparams_filename='../src/config/laptop_config.json',\n",
    "#     device='cpu',\n",
    "# )\n",
    "# pred_lap = laptop_agent.get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c62a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restaurant_agent = InferenceAgent(\n",
    "#     proj_path=str(PROJ_PATH),\n",
    "#     ckpt_filename='epoch=4-val_loss=0.6445-val_acc=0.8003-val_macro_f1=0.7335-val_micro_f1=0.8003.ckpt',\n",
    "#     ckpt_dirname='model/restaurent',\n",
    "#     hparams_filename='../src/config/restaurant_config.json',\n",
    "#     device='cpu',\n",
    "# )\n",
    "# pred_res = restaurant_agent.get_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265514d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
