{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea9b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2477997/2032842600.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJ_PATH=/home/hoang/github/BERT_ABSA\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re, datetime, random, gzip, json\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from itertools import accumulate\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "\n",
    "from time import time\n",
    "from math import ceil\n",
    "from multiprocessing import Pool\n",
    "from sentence_transformers import SentenceTransformer, models, losses, InputExample\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "\n",
    "PROJ_PATH = Path(os.path.join(re.sub(\"/BERT_ABSA.*$\", '', os.getcwd()), 'BERT_ABSA'))\n",
    "print(f'PROJ_PATH={PROJ_PATH}')\n",
    "sys.path.insert(1, str(PROJ_PATH))\n",
    "sys.path.insert(1, str(PROJ_PATH/'src'))\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21cf9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob.glob('../model/restaurants/*.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1dd32c",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762e5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def tokenization(text):\n",
    "    text = text.strip().lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def bucketize(text_length):\n",
    "    if text_length < 15:\n",
    "        return 0\n",
    "    elif text_length < 20:\n",
    "        return 1\n",
    "    elif text_length < 30:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "def get_pred_label(x):\n",
    "    if max([x.pred_0, x.pred_1, x.pred_2]) == x.pred_0:\n",
    "        return 'negative'\n",
    "    elif max([x.pred_0, x.pred_1, x.pred_2]) == x.pred_1:\n",
    "        return 'neutral'\n",
    "    else: return 'positive'\n",
    "    \n",
    "def get_pred_label_id(x):\n",
    "    if max([x.pred_0, x.pred_1, x.pred_2]) == x.pred_0:\n",
    "        return 0\n",
    "    elif max([x.pred_0, x.pred_1, x.pred_2]) == x.pred_1:\n",
    "        return 1\n",
    "    else: return 2\n",
    "    \n",
    "def read_base_prediction(dataset='restaurant'):\n",
    "    model_dict = {\n",
    "        'bert': '../output/bert_{}.csv'.format(dataset),\n",
    "        'syn': '../output/syn_{}.csv'.format(dataset),\n",
    "        'sem': '../output/sem_{}.csv'.format(dataset),\n",
    "    }\n",
    "    \n",
    "    tmp = [pd.read_csv(list(model_dict.values())[0])[['id', 'text', 'term', 'label_id', 'label', 'tvt']]]\n",
    "    for n, p in model_dict.items():\n",
    "        tmp.append(pd.read_csv(p)[['pred_0', 'pred_1', 'pred_2']].rename(columns={\n",
    "            'pred_0': f'{n}_0', 'pred_1': f'{n}_1', 'pred_2': f'{n}_2'}))\n",
    "    df = pd.concat(tmp, axis=1)\n",
    "    df['label_id'] = df['label'].map({j:i for i,j in labelid2str.items()})\n",
    "    df['tokens'] = df['text'].apply(tokenization)\n",
    "    df['text_length'] = df['tokens'].apply(lambda x: len(x))\n",
    "    df['length_group'] = df['text_length'].apply(bucketize)\n",
    "    \n",
    "    df['is_neg'] = df['label_id'].apply(lambda x: int(x==0))\n",
    "    df['is_neu'] = df['label_id'].apply(lambda x: int(x==1))\n",
    "    df['is_pos'] = df['label_id'].apply(lambda x: int(x==2))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a99ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tvt_idx(df, tvt_col='tvt'):\n",
    "    '''\n",
    "    Get train/val/test indexes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        [('train', train_idx), ('val', val_idx), ('test', test_idx)]\n",
    "        \n",
    "    '''\n",
    "    tvt_idx = [\n",
    "        ('train', df['tvt']=='train'),\n",
    "        ('val', df['tvt']=='val'),\n",
    "        ('test', df['tvt']=='test'),\n",
    "    ]\n",
    "    return tvt_idx  \n",
    "\n",
    "def get_feature_importance_from_model(fmodel, sort=True):\n",
    "    model = fmodel['model']\n",
    "    feature_cnames = fmodel['cname_feats']\n",
    "    pd_imp = pd.DataFrame(list(model.get_booster().get_score(importance_type='gain').items()), columns=['feature', 'importance'])\n",
    "    pd_imp['feature'] = pd_imp['feature'].replace({'f{}'.format(str(i)): feature_cnames[i] for i in range(len(feature_cnames))}) # for ranker\n",
    "    if sort:\n",
    "        pd_imp = pd_imp.sort_values('importance', ascending=False)\n",
    "    return pd_imp\n",
    "\n",
    "def compute_evaluation_metrics(model, best_ntree, x_train, y_train, x_val, y_val, x_test, y_test, is_binary):\n",
    "    train_score = model.predict_proba(x_train, ntree_limit=best_ntree)\n",
    "    train_pred = model.predict(x_train, ntree_limit=best_ntree)\n",
    "    val_score = model.predict_proba(x_val, ntree_limit=best_ntree)\n",
    "    val_pred = model.predict(x_val, ntree_limit=best_ntree)\n",
    "    test_score = model.predict_proba(x_test, ntree_limit=best_ntree)\n",
    "    test_pred = model.predict(x_test, ntree_limit=best_ntree)\n",
    "    \n",
    "    if is_binary:\n",
    "        train_auc = roc_auc_score(y_true=y_train, y_score=train_score[:, 1])\n",
    "        val_auc = roc_auc_score(y_true=y_val, y_score=val_score[:, 1])\n",
    "        test_auc = roc_auc_score(y_true=y_test, y_score=test_score[:, 1])\n",
    "    else:\n",
    "        train_auc = roc_auc_score(y_true=y_train, y_score=train_score, multi_class='ovo')\n",
    "        val_auc = roc_auc_score(y_true=y_val, y_score=val_score, multi_class='ovo')\n",
    "        test_auc = roc_auc_score(y_true=y_test, y_score=test_score, multi_class='ovo')\n",
    "    \n",
    "    train_acc = accuracy_score(y_true=y_train, y_pred=train_pred)\n",
    "    val_acc = accuracy_score(y_true=y_val, y_pred=val_pred)\n",
    "    test_acc = accuracy_score(y_true=y_test, y_pred=test_pred)\n",
    "    return train_auc, train_acc, val_auc, val_acc, test_auc, test_acc\n",
    "\n",
    "def train_xgb(dfXY, tvt_idx, cname_feats, cname_target='label', option_init={}, option_fit={}):\n",
    "    default_option_fit = {\n",
    "        'eval_metric': 'auc',\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 20,\n",
    "    }\n",
    "    default_option_init = {\n",
    "        'objective': 'binary:logistic',\n",
    "#         'max_depth': 5,\n",
    "#         'n_estimators': 200,   \n",
    "#         'learning_rate': 0.001,\n",
    "#         'gamma': 0.0,\n",
    "#         'min_child_weight': 10,\n",
    "#         'subsample': 0.1,\n",
    "#         'tree_method': 'hist',\n",
    "#         'colsample_bytree': 0.5,\n",
    "#         'colsample_bylevel': 0.5,\n",
    "#         'reg_alpha': 0.0,\n",
    "#         'reg_lambda': 1.0,\n",
    "        'random_state': 0,\n",
    "        'n_jobs': 32\n",
    "    }\n",
    "    default_option_fit.update(option_fit)\n",
    "    default_option_init.update(option_init)\n",
    "    option_fit = default_option_fit\n",
    "    option_init = default_option_init\n",
    "    \n",
    "    if dfXY[cname_target].nunique() == 2:\n",
    "        is_binary = True\n",
    "    else:\n",
    "        is_binary = False\n",
    "    # train/test\n",
    "    x_train = dfXY[tvt_idx[0][1]][cname_feats].values\n",
    "    y_train = dfXY[tvt_idx[0][1]][cname_target].values.astype(\"i4\")\n",
    "    x_val = dfXY[tvt_idx[1][1]][cname_feats].values\n",
    "    y_val = dfXY[tvt_idx[1][1]][cname_target].values.astype(\"i4\")\n",
    "    x_test = dfXY[tvt_idx[2][1]][cname_feats].values\n",
    "    y_test = dfXY[tvt_idx[2][1]][cname_target].values.astype(\"i4\")\n",
    "    \n",
    "    # classify\n",
    "    eval_set = [\n",
    "        (x_train, y_train),\n",
    "        (x_val, y_val),\n",
    "    ]\n",
    "    \n",
    "    model = xgb.XGBClassifier(**option_init)\n",
    "    model.fit(x_train, y_train, eval_set=eval_set, **option_fit)\n",
    "    best_ntree = model.get_booster().best_ntree_limit  \n",
    "    \n",
    "    train_auc, train_acc, val_auc, val_acc, test_auc, test_acc = compute_evaluation_metrics(\n",
    "        model, best_ntree, x_train, y_train, x_val, y_val, x_test, y_test, is_binary)\n",
    "    print('n_features n_train n_val n_test n_tree train_auc train_acc val_auc val_acc test_auc test_acc')\n",
    "    print('{} {} {} {} {} {:.5f} {:.5f} {:.5f} {:.5f} {:.5f} {:.5f}'.format(\n",
    "        len(cname_feats), x_train.shape[0], x_val.shape[0], x_test.shape[0], best_ntree,\n",
    "        train_auc, train_acc, val_auc, val_acc, test_auc, test_acc))\n",
    "    \n",
    "    # track\n",
    "    fmodel = {\n",
    "        'model': model,\n",
    "        'cname_target': cname_target,\n",
    "        'cname_feats': cname_feats,  \n",
    "    }\n",
    "    return fmodel\n",
    "\n",
    "def compute_evaluation_metrics_reg(model, best_ntree, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "    pred_train = model.predict(x_train, ntree_limit=best_ntree)\n",
    "    pred_val = model.predict(x_val, ntree_limit=best_ntree)\n",
    "    pred_test = model.predict(x_test, ntree_limit=best_ntree)\n",
    "    \n",
    "    mse_train = mean_squared_error(y_true=y_train, y_pred=pred_train)\n",
    "    corr_train = pearsonr(y_train, pred_train)[0]\n",
    "    mse_val = mean_squared_error(y_true=y_val, y_pred=pred_val)\n",
    "    corr_val = pearsonr(y_val, pred_val)[0]\n",
    "    mse_test = mean_squared_error(y_true=y_test, y_pred=pred_test)\n",
    "    corr_test = pearsonr(y_test, pred_test)[0]\n",
    "    return mse_train, corr_train, mse_val, corr_val, mse_test, corr_test\n",
    "\n",
    "def train_xgb_regressor(dfXY, tvt_idx, cname_feats, cname_target='label', option_init={}, option_fit={}):\n",
    "    default_option_fit = {\n",
    "        'eval_metric': 'rmse',\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 20,\n",
    "    }\n",
    "    default_option_init = {\n",
    "        'objective': 'reg:squarederror',\n",
    "#         'max_depth': 5,\n",
    "#         'n_estimators': 200,   \n",
    "#         'learning_rate': 0.001,\n",
    "#         'gamma': 0.0,\n",
    "#         'min_child_weight': 10,\n",
    "#         'subsample': 0.1,\n",
    "#         'tree_method': 'hist',\n",
    "#         'colsample_bytree': 0.5,\n",
    "#         'colsample_bylevel': 0.5,\n",
    "#         'reg_alpha': 0.0,\n",
    "#         'reg_lambda': 1.0,\n",
    "        'random_state': 0,\n",
    "        'n_jobs': 32\n",
    "    }\n",
    "    default_option_fit.update(option_fit)\n",
    "    default_option_init.update(option_init)\n",
    "    option_fit = default_option_fit\n",
    "    option_init = default_option_init\n",
    "    \n",
    "    # train/test\n",
    "    x_train = dfXY[tvt_idx[0][1]][cname_feats].values\n",
    "    y_train = dfXY[tvt_idx[0][1]][cname_target].values.astype(\"i4\")\n",
    "    x_val = dfXY[tvt_idx[1][1]][cname_feats].values\n",
    "    y_val = dfXY[tvt_idx[1][1]][cname_target].values.astype(\"i4\")\n",
    "    x_test = dfXY[tvt_idx[2][1]][cname_feats].values\n",
    "    y_test = dfXY[tvt_idx[2][1]][cname_target].values.astype(\"i4\")\n",
    "    \n",
    "    # classify\n",
    "    eval_set = [\n",
    "        (x_train, y_train),\n",
    "        (x_val, y_val),\n",
    "    ]\n",
    "    \n",
    "    model = xgb.XGBRegressor(**option_init)\n",
    "    model.fit(x_train, y_train, eval_set=eval_set, **option_fit)\n",
    "    best_ntree = model.get_booster().best_ntree_limit  \n",
    "    \n",
    "    mse_train, corr_train, mse_val, corr_val, mse_test, corr_test = compute_evaluation_metrics_reg(\n",
    "        model, best_ntree, x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "    print('n_features n_train n_val n_test n_tree mse_train corr_train mse_val corr_val mse_test corr_test')\n",
    "    print('{} {} {} {} {} {:.5f} {:.5f} {:.5f} {:.5f} {:.5f} {:.5f}'.format(\n",
    "        len(cname_feats), x_train.shape[0], x_val.shape[0], x_test.shape[0], best_ntree,\n",
    "        mse_train, corr_train, mse_val, corr_val, mse_test, corr_test))\n",
    "   \n",
    "    # track\n",
    "    fmodel = {\n",
    "        'model': model,\n",
    "        'cname_target': cname_target,\n",
    "        'cname_feats': cname_feats,  \n",
    "    }\n",
    "    return fmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861c313",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39f09d83",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th colspan=\"3\" halign=\"left\">negative</th>\n",
       "      <th colspan=\"3\" halign=\"left\">neutral</th>\n",
       "      <th colspan=\"3\" halign=\"left\">positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tvt</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>laptops</th>\n",
       "      <td>128</td>\n",
       "      <td>693</td>\n",
       "      <td>177</td>\n",
       "      <td>169</td>\n",
       "      <td>382</td>\n",
       "      <td>82</td>\n",
       "      <td>341</td>\n",
       "      <td>787</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restaurants</th>\n",
       "      <td>196</td>\n",
       "      <td>647</td>\n",
       "      <td>160</td>\n",
       "      <td>196</td>\n",
       "      <td>500</td>\n",
       "      <td>137</td>\n",
       "      <td>728</td>\n",
       "      <td>1739</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label       negative            neutral            positive           \n",
       "tvt             test train  val    test train  val     test train  val\n",
       "ds                                                                    \n",
       "laptops          128   693  177     169   382   82      341   787  207\n",
       "restaurants      196   647  160     196   500  137      728  1739  425"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.read_csv('../output/bert_restaurant.csv')\n",
    "df_res['ds'] = 'restaurants'\n",
    "df_lap = pd.read_csv('../output/bert_laptop.csv')\n",
    "df_lap['ds'] = 'laptops'\n",
    "df = pd.concat([df_res, df_lap])\n",
    "\n",
    "df.pivot_table(index='ds', columns=['label', 'tvt'], values='id', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d23bb5e3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2.0), (10, 9.0), (20, 11.0), (30, 14.0), (40, 16.0), (50, 18.0), (60, 20.0), (70, 23.0), (80, 27.0), (90, 32.0), (100, 79.0)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_label</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>921</td>\n",
       "      <td>52</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>79</td>\n",
       "      <td>681</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>59</td>\n",
       "      <td>99</td>\n",
       "      <td>2734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_label  negative  neutral  positive\n",
       "label                                  \n",
       "negative         921       52        30\n",
       "neutral           79      681        73\n",
       "positive          59       99      2734"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../output/bert_restaurant.csv')\n",
    "labelid2str = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "df['label_id'] = df['label'].map({j:i for i,j in labelid2str.items()})\n",
    "df['pred_label'] = df[['pred_0', 'pred_1', 'pred_2']].apply(get_pred_label, axis=1)\n",
    "df['pred_id'] = df['pred_label'].map({j:i for i,j in labelid2str.items()})\n",
    "df['tokens'] = df['text'].apply(tokenization)\n",
    "df['text_length'] = df['tokens'].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "p = range(0, 101, 10)\n",
    "print(list(zip(p, np.percentile(df['text_length'], p))))\n",
    "\n",
    "\n",
    "i1 = df['label']=='negative'\n",
    "i2 = df['label']=='neutral'\n",
    "i3 = df['label']=='positive'\n",
    "col = 'text_length'\n",
    "df[i1][col].hist(alpha=0.5, label='positive')\n",
    "df[i2][col].hist(alpha=0.5, label='neutral')\n",
    "df[i3][col].hist(alpha=0.5, label='negative')\n",
    "plt.legend()\n",
    "plt.title('Distribution of sentence length')\n",
    "plt.show()\n",
    "\n",
    "pred_results = df.groupby(['label', 'pred_label'], as_index=False).size().sort_values('size', ascending=False)\n",
    "display(pred_results.pivot_table(index='label', columns='pred_label', values='size', aggfunc='sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "503ea89c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3.0), (10, 9.0), (20, 12.0), (30, 14.0), (40, 16.0), (50, 19.0), (60, 21.0), (70, 24.0), (80, 29.0), (90, 37.0), (100, 83.0)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_label</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>924</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>88</td>\n",
       "      <td>504</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>48</td>\n",
       "      <td>53</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_label  negative  neutral  positive\n",
       "label                                  \n",
       "negative         924       36        38\n",
       "neutral           88      504        41\n",
       "positive          48       53      1234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../output/bert_laptop.csv')\n",
    "labelid2str = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "df['label_id'] = df['label'].map({j:i for i,j in labelid2str.items()})\n",
    "df['pred_label'] = df[['pred_0', 'pred_1', 'pred_2']].apply(get_pred_label, axis=1)\n",
    "df['pred_id'] = df['pred_label'].map({j:i for i,j in labelid2str.items()})\n",
    "df['tokens'] = df['text'].apply(tokenization)\n",
    "df['text_length'] = df['tokens'].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "p = range(0, 101, 10)\n",
    "print(list(zip(p, np.percentile(df['text_length'], p))))\n",
    "\n",
    "\n",
    "i1 = df['label']=='negative'\n",
    "i2 = df['label']=='neutral'\n",
    "i3 = df['label']=='positive'\n",
    "col = 'text_length'\n",
    "df[i1][col].hist(alpha=0.5, label='positive')\n",
    "df[i2][col].hist(alpha=0.5, label='neutral')\n",
    "df[i3][col].hist(alpha=0.5, label='negative')\n",
    "plt.legend()\n",
    "plt.title('Distribution of sentence length')\n",
    "plt.show()\n",
    "\n",
    "pred_results = df.groupby(['label', 'pred_label'], as_index=False).size().sort_values('size', ascending=False)\n",
    "display(pred_results.pivot_table(index='label', columns='pred_label', values='size', aggfunc='sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "949f96e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# col1 = 'pred_0'\n",
    "# col2 = 'pred_1'\n",
    "# col3 = 'pred_2'\n",
    "# df[i1][col1].hist(alpha=0.5, label='positive')\n",
    "# df[i1][col2].hist(alpha=0.5, label='negative')\n",
    "# df[i1][col3].hist(alpha=0.5, label='neutral')\n",
    "# plt.legend()\n",
    "# plt.title('Distribution of prediction for positive sentences')\n",
    "# plt.show()\n",
    "\n",
    "# i1 = df['label']=='positive'\n",
    "# i2 = df['label']=='neutral'\n",
    "# i3 = df['label']=='negative'\n",
    "# col1 = 'pred_0'\n",
    "# col2 = 'pred_1'\n",
    "# col3 = 'pred_2'\n",
    "# df[i2][col1].hist(alpha=0.5, label='positive')\n",
    "# df[i2][col2].hist(alpha=0.5, label='negative')\n",
    "# df[i2][col3].hist(alpha=0.5, label='neutral')\n",
    "# plt.legend()\n",
    "# plt.title('Distribution of prediction for neutral sentences')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# i1 = df['label']=='positive'\n",
    "# i2 = df['label']=='neutral'\n",
    "# i3 = df['label']=='negative'\n",
    "# col1 = 'pred_0'\n",
    "# col2 = 'pred_1'\n",
    "# col3 = 'pred_2'\n",
    "# df[i3][col1].hist(alpha=0.5, label='positive')\n",
    "# df[i3][col2].hist(alpha=0.5, label='negative')\n",
    "# df[i3][col3].hist(alpha=0.5, label='neutral')\n",
    "# plt.legend()\n",
    "# plt.title('Distribution of prediction for negative sentences')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d3ad5",
   "metadata": {},
   "source": [
    "## Ensemble learning - restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5168fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>bert_0</th>\n",
       "      <th>bert_1</th>\n",
       "      <th>bert_2</th>\n",
       "      <th>syn_0</th>\n",
       "      <th>...</th>\n",
       "      <th>syn_2</th>\n",
       "      <th>sem_0</th>\n",
       "      <th>sem_1</th>\n",
       "      <th>sem_2</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text_length</th>\n",
       "      <th>length_group</th>\n",
       "      <th>is_neg</th>\n",
       "      <th>is_neu</th>\n",
       "      <th>is_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1909</td>\n",
       "      <td>The entire dining experience was wonderful!</td>\n",
       "      <td>dining experience</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.997196</td>\n",
       "      <td>[the, entire, dining, experience, was, wonderf...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2492</td>\n",
       "      <td>The chicken and steak were seasoned and cooked...</td>\n",
       "      <td>steak</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.999115</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.997441</td>\n",
       "      <td>[the, chicken, and, steak, were, seasoned, and...</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1894</td>\n",
       "      <td>The place is a BISTRO which means: simple dish...</td>\n",
       "      <td>wine</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.999080</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999155</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.997257</td>\n",
       "      <td>[the, place, is, a, bistro, which, means, :, s...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2871</td>\n",
       "      <td>Leon is an East Village gem: casual but hip, w...</td>\n",
       "      <td>atmosphere</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.999126</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.997257</td>\n",
       "      <td>[leon, is, an, east, village, gem, :, casual, ...</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2449</td>\n",
       "      <td>The Waitstaff were very nice and suggested swo...</td>\n",
       "      <td>swordfish</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.006762</td>\n",
       "      <td>0.992523</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997352</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.994418</td>\n",
       "      <td>[the, waitstaff, were, very, nice, and, sugges...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text               term  \\\n",
       "0  1909        The entire dining experience was wonderful!  dining experience   \n",
       "1  2492  The chicken and steak were seasoned and cooked...              steak   \n",
       "2  1894  The place is a BISTRO which means: simple dish...               wine   \n",
       "3  2871  Leon is an East Village gem: casual but hip, w...         atmosphere   \n",
       "4  2449  The Waitstaff were very nice and suggested swo...          swordfish   \n",
       "\n",
       "   label_id     label    tvt    bert_0    bert_1    bert_2     syn_0  ...  \\\n",
       "0         2  positive  train  0.000114  0.000763  0.999123  0.000153  ...   \n",
       "1         2  positive  train  0.000115  0.000770  0.999115  0.000141  ...   \n",
       "2         2  positive  train  0.000120  0.000800  0.999080  0.000207  ...   \n",
       "3         2  positive  train  0.000114  0.000760  0.999126  0.000140  ...   \n",
       "4         2  positive  train  0.000715  0.006762  0.992523  0.000598  ...   \n",
       "\n",
       "      syn_2     sem_0     sem_1     sem_2  \\\n",
       "0  0.999390  0.001158  0.001646  0.997196   \n",
       "1  0.999435  0.000971  0.001588  0.997441   \n",
       "2  0.999155  0.001224  0.001519  0.997257   \n",
       "3  0.999442  0.001197  0.001547  0.997257   \n",
       "4  0.997352  0.000509  0.005073  0.994418   \n",
       "\n",
       "                                              tokens text_length  \\\n",
       "0  [the, entire, dining, experience, was, wonderf...           7   \n",
       "1  [the, chicken, and, steak, were, seasoned, and...          21   \n",
       "2  [the, place, is, a, bistro, which, means, :, s...          19   \n",
       "3  [leon, is, an, east, village, gem, :, casual, ...          28   \n",
       "4  [the, waitstaff, were, very, nice, and, sugges...          16   \n",
       "\n",
       "   length_group  is_neg  is_neu  is_pos  \n",
       "0             0       0       0       1  \n",
       "1             2       0       0       1  \n",
       "2             1       0       0       1  \n",
       "3             2       0       0       1  \n",
       "4             1       0       0       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelid2str = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "df = read_base_prediction()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232ab761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "Test AUC: 0.9215537863497048\n",
      "Test ACC: 0.8428571428571429\n",
      "Test CORR: 0.7830828503354347\n",
      "\n",
      "syn\n",
      "Test AUC: 0.9186951517263107\n",
      "Test ACC: 0.85\n",
      "Test CORR: 0.7903537333835158\n",
      "\n",
      "sem\n",
      "Test AUC: 0.9137618940825938\n",
      "Test ACC: 0.8526785714285714\n",
      "Test CORR: 0.8006081889166599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = ['bert', 'syn', 'sem']\n",
    "i_test = df['tvt']=='test'\n",
    "for n in model_name:\n",
    "    print(n)\n",
    "    tmp = df.copy()\n",
    "    tmp = tmp.rename(columns={f'{n}_0': 'pred_0', f'{n}_1': 'pred_1', f'{n}_2': 'pred_2'})\n",
    "    tmp['pred_label'] = tmp[['pred_0', 'pred_1', 'pred_2']].apply(get_pred_label, axis=1)\n",
    "    tmp['pred_id'] = tmp['pred_label'].map({j:i for i,j in labelid2str.items()})\n",
    "    test_auc = roc_auc_score(\n",
    "        y_true=tmp[i_test]['label_id'], y_score=tmp[i_test][['pred_0', 'pred_1', 'pred_2']], multi_class='ovo')\n",
    "    test_acc = accuracy_score(y_true=tmp[i_test]['label_id'], y_pred=tmp[i_test].apply(get_pred_label_id, axis=1))\n",
    "    test_corr = pearsonr(tmp[i_test]['label_id'], tmp[i_test].apply(get_pred_label_id, axis=1))[0]\n",
    "    print(f'Test AUC: {test_auc}')\n",
    "    print(f'Test ACC: {test_acc}')\n",
    "    print(f'Test CORR: {test_corr}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0fea377",
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_cols = ['id', 'text', 'term', 'label_id', 'label', 'tvt', 'tokens', 'is_neg', 'is_neu', 'is_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00d508eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features n_train n_val n_test n_tree train_auc train_acc val_auc val_acc test_auc test_acc\n",
      "11 2886 722 1120 22 0.99855 0.99272 0.89788 0.80332 0.91885 0.86696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/py38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/hoang/miniconda2/envs/py38/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sem_2</td>\n",
       "      <td>120.978851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sem_1</td>\n",
       "      <td>98.217224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>syn_2</td>\n",
       "      <td>85.261421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert_0</td>\n",
       "      <td>79.796188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sem_0</td>\n",
       "      <td>79.204941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>syn_0</td>\n",
       "      <td>70.555641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_2</td>\n",
       "      <td>65.485435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert_1</td>\n",
       "      <td>59.234016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>syn_1</td>\n",
       "      <td>56.462891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>text_length</td>\n",
       "      <td>1.364058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length_group</td>\n",
       "      <td>0.859806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "6          sem_2  120.978851\n",
       "5          sem_1   98.217224\n",
       "9          syn_2   85.261421\n",
       "0         bert_0   79.796188\n",
       "4          sem_0   79.204941\n",
       "7          syn_0   70.555641\n",
       "2         bert_2   65.485435\n",
       "1         bert_1   59.234016\n",
       "8          syn_1   56.462891\n",
       "10   text_length    1.364058\n",
       "3   length_group    0.859806"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tvt_idx = get_tvt_idx(df)\n",
    "cname_feats = sorted([c for c in df.columns if c not in excl_cols and not c.startswith('pred_')])\n",
    "option_init = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bylevel': 0.3,\n",
    "    'random_state': 0,\n",
    "}\n",
    "fmodel_clf = train_xgb(\n",
    "    dfXY=df, tvt_idx=tvt_idx, cname_feats=cname_feats, cname_target='label_id', option_init=option_init)\n",
    "display(get_feature_importance_from_model(fmodel_clf))\n",
    "if False:\n",
    "    pd.to_pickle(fmodel_clf, '../model/ensemble_restaurants.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16dba7",
   "metadata": {},
   "source": [
    "## Ensemble learning - Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "264395c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>term</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "      <th>tvt</th>\n",
       "      <th>bert_0</th>\n",
       "      <th>bert_1</th>\n",
       "      <th>bert_2</th>\n",
       "      <th>syn_0</th>\n",
       "      <th>...</th>\n",
       "      <th>syn_2</th>\n",
       "      <th>sem_0</th>\n",
       "      <th>sem_1</th>\n",
       "      <th>sem_2</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text_length</th>\n",
       "      <th>length_group</th>\n",
       "      <th>is_neg</th>\n",
       "      <th>is_neu</th>\n",
       "      <th>is_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2970</td>\n",
       "      <td>I did not have to call the support line at all.</td>\n",
       "      <td>support line</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>train</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078817</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.997346</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>[i, did, not, have, to, call, the, support, li...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2338</td>\n",
       "      <td>I take it everywhere with me because it's so e...</td>\n",
       "      <td>carry</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.007021</td>\n",
       "      <td>0.011967</td>\n",
       "      <td>0.981011</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994666</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>[i, take, it, everywhere, with, me, because, i...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2674</td>\n",
       "      <td>One drawback I noticed was sound quality via USB.</td>\n",
       "      <td>sound quality via USB</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>train</td>\n",
       "      <td>0.972162</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.021693</td>\n",
       "      <td>0.981453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.997571</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>[one, drawback, i, noticed, was, sound, qualit...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3011</td>\n",
       "      <td>Great OS, fabulous improvements to the existin...</td>\n",
       "      <td>OS</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.043205</td>\n",
       "      <td>0.943595</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997985</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.999073</td>\n",
       "      <td>[great, os, ,, fabulous, improvements, to, the...</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>I even got my teenage son one, because of the ...</td>\n",
       "      <td>Photobooth</td>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "      <td>train</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.985201</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997125</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.999099</td>\n",
       "      <td>[i, even, got, my, teenage, son, one, ,, becau...</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  \\\n",
       "0  2970    I did not have to call the support line at all.   \n",
       "1  2338  I take it everywhere with me because it's so e...   \n",
       "2  2674  One drawback I noticed was sound quality via USB.   \n",
       "3  3011  Great OS, fabulous improvements to the existin...   \n",
       "4    76  I even got my teenage son one, because of the ...   \n",
       "\n",
       "                    term  label_id     label    tvt    bert_0    bert_1  \\\n",
       "0           support line         1   neutral  train  0.013033  0.977031   \n",
       "1                  carry         2  positive  train  0.007021  0.011967   \n",
       "2  sound quality via USB         0  negative  train  0.972162  0.006145   \n",
       "3                     OS         2  positive  train  0.013200  0.043205   \n",
       "4             Photobooth         2  positive  train  0.007652  0.007146   \n",
       "\n",
       "     bert_2     syn_0  ...     syn_2     sem_0     sem_1     sem_2  \\\n",
       "0  0.009937  0.024876  ...  0.078817  0.001159  0.997346  0.001495   \n",
       "1  0.981011  0.000242  ...  0.994666  0.000404  0.000521  0.999075   \n",
       "2  0.021693  0.981453  ...  0.005989  0.997571  0.001612  0.000817   \n",
       "3  0.943595  0.000195  ...  0.997985  0.000541  0.000386  0.999073   \n",
       "4  0.985201  0.000148  ...  0.997125  0.000435  0.000465  0.999099   \n",
       "\n",
       "                                              tokens text_length  \\\n",
       "0  [i, did, not, have, to, call, the, support, li...          12   \n",
       "1  [i, take, it, everywhere, with, me, because, i...          14   \n",
       "2  [one, drawback, i, noticed, was, sound, qualit...          10   \n",
       "3  [great, os, ,, fabulous, improvements, to, the...          20   \n",
       "4  [i, even, got, my, teenage, son, one, ,, becau...          27   \n",
       "\n",
       "   length_group  is_neg  is_neu  is_pos  \n",
       "0             0       0       1       0  \n",
       "1             0       0       0       1  \n",
       "2             0       1       0       0  \n",
       "3             2       0       0       1  \n",
       "4             2       0       0       1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelid2str = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "df = read_base_prediction('laptop')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c5eb78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "Test AUC: 0.8988439703390075\n",
      "Test ACC: 0.7774294670846394\n",
      "Test CORR: 0.72685876734475\n",
      "\n",
      "syn\n",
      "Test AUC: 0.8894568779029077\n",
      "Test ACC: 0.7789968652037618\n",
      "Test CORR: 0.7328292725606129\n",
      "\n",
      "sem\n",
      "Test AUC: 0.8899405753469029\n",
      "Test ACC: 0.7899686520376176\n",
      "Test CORR: 0.725577290338284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = ['bert', 'syn', 'sem']\n",
    "i_test = df['tvt']=='test'\n",
    "for n in model_name:\n",
    "    print(n)\n",
    "    tmp = df.copy()\n",
    "    tmp = tmp.rename(columns={f'{n}_0': 'pred_0', f'{n}_1': 'pred_1', f'{n}_2': 'pred_2'})\n",
    "    tmp['pred_label'] = tmp[['pred_0', 'pred_1', 'pred_2']].apply(get_pred_label, axis=1)\n",
    "    tmp['pred_id'] = tmp['pred_label'].map({j:i for i,j in labelid2str.items()})\n",
    "    test_auc = roc_auc_score(\n",
    "        y_true=tmp[i_test]['label_id'], y_score=tmp[i_test][['pred_0', 'pred_1', 'pred_2']], multi_class='ovo')\n",
    "    test_acc = accuracy_score(y_true=tmp[i_test]['label_id'], y_pred=tmp[i_test].apply(get_pred_label_id, axis=1))\n",
    "    test_corr = pearsonr(tmp[i_test]['label_id'], tmp[i_test].apply(get_pred_label_id, axis=1))[0]\n",
    "    print(f'Test AUC: {test_auc}')\n",
    "    print(f'Test ACC: {test_acc}')\n",
    "    print(f'Test CORR: {test_corr}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aefb5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "excl_cols = ['id', 'text', 'term', 'label_id', 'label', 'tvt', 'tokens', 'is_neg', 'is_neu', 'is_pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44ba4516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features n_train n_val n_test n_tree train_auc train_acc val_auc val_acc test_auc test_acc\n",
      "11 1862 466 638 21 0.99885 0.98711 0.90881 0.78755 0.89483 0.79781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/py38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/hoang/miniconda2/envs/py38/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>syn_0</td>\n",
       "      <td>81.614334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>syn_1</td>\n",
       "      <td>70.301811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>syn_2</td>\n",
       "      <td>65.288406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sem_2</td>\n",
       "      <td>63.876202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sem_0</td>\n",
       "      <td>58.641983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_2</td>\n",
       "      <td>53.528976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert_0</td>\n",
       "      <td>51.229324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert_1</td>\n",
       "      <td>48.101238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sem_1</td>\n",
       "      <td>43.510239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>text_length</td>\n",
       "      <td>1.050979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length_group</td>\n",
       "      <td>0.552155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "7          syn_0   81.614334\n",
       "8          syn_1   70.301811\n",
       "9          syn_2   65.288406\n",
       "6          sem_2   63.876202\n",
       "4          sem_0   58.641983\n",
       "2         bert_2   53.528976\n",
       "0         bert_0   51.229324\n",
       "1         bert_1   48.101238\n",
       "5          sem_1   43.510239\n",
       "10   text_length    1.050979\n",
       "3   length_group    0.552155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tvt_idx = get_tvt_idx(df)\n",
    "cname_feats = sorted([c for c in df.columns if c not in excl_cols and not c.startswith('pred_')])\n",
    "option_init = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bylevel': 0.3,\n",
    "}\n",
    "fmodel_clf = train_xgb(\n",
    "    dfXY=df, tvt_idx=tvt_idx, cname_feats=cname_feats, cname_target='label_id', option_init=option_init)\n",
    "display(get_feature_importance_from_model(fmodel_clf))\n",
    "if False:\n",
    "    pd.to_pickle(fmodel_clf, '../model/ensemble_laptops.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f53757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features n_train n_val n_test n_tree train_auc train_acc val_auc val_acc test_auc test_acc\n",
      "14 1862 466 638 8 0.99870 0.98980 0.89541 0.78112 0.88822 0.79154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda2/envs/py38/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/hoang/miniconda2/envs/py38/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sem_0</td>\n",
       "      <td>108.387306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>syn_0</td>\n",
       "      <td>106.763435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>syn_2</td>\n",
       "      <td>100.280754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pred_neg</td>\n",
       "      <td>97.356911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pred_pos</td>\n",
       "      <td>92.012566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert_0</td>\n",
       "      <td>73.423386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sem_2</td>\n",
       "      <td>72.179443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_2</td>\n",
       "      <td>70.953064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>syn_1</td>\n",
       "      <td>59.743412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pred_neu</td>\n",
       "      <td>53.850788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sem_1</td>\n",
       "      <td>46.393440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert_1</td>\n",
       "      <td>25.518335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text_length</td>\n",
       "      <td>2.257998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>length_group</td>\n",
       "      <td>0.636267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance\n",
       "7          sem_0  108.387306\n",
       "10         syn_0  106.763435\n",
       "12         syn_2  100.280754\n",
       "4       pred_neg   97.356911\n",
       "6       pred_pos   92.012566\n",
       "0         bert_0   73.423386\n",
       "9          sem_2   72.179443\n",
       "2         bert_2   70.953064\n",
       "11         syn_1   59.743412\n",
       "5       pred_neu   53.850788\n",
       "8          sem_1   46.393440\n",
       "1         bert_1   25.518335\n",
       "13   text_length    2.257998\n",
       "3   length_group    0.636267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tvt_idx = get_tvt_idx(df)\n",
    "cname_feats = sorted([c for c in df.columns if c not in excl_cols and c not in ])\n",
    "option_init = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bylevel': 0.3,\n",
    "#     'random_state': 0,\n",
    "}\n",
    "fmodel_clf = train_xgb(\n",
    "    dfXY=df, tvt_idx=tvt_idx, cname_feats=cname_feats, cname_target='label_id', option_init=option_init)\n",
    "display(get_feature_importance_from_model(fmodel_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81bbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0220e9fc",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6527f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvt_idx = get_tvt_idx(df)\n",
    "# cname_feats = sorted([c for c in df.columns if c not in excl_cols and not c.startswith('pred_')])\n",
    "# option_init = {\n",
    "#     'n_estimators': 1000,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'subsample': 0.9,\n",
    "#     'colsample_bytree': 0.9,\n",
    "#     'colsample_bylevel': 0.9,\n",
    "#     'random_state': 0,\n",
    "# }\n",
    "# fmodel_neg = train_xgb(\n",
    "#     dfXY=df, tvt_idx=tvt_idx, cname_feats=cname_feats, cname_target='is_neg', option_init=option_init)\n",
    "\n",
    "# tvt_idx = get_tvt_idx(df)\n",
    "# cname_feats = sorted([c for c in df.columns if c not in excl_cols and not c.startswith('pred_')])\n",
    "# option_init = {\n",
    "#     'n_estimators': 1000,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'subsample': 0.9,\n",
    "#     'colsample_bytree': 0.9,\n",
    "#     'colsample_bylevel': 0.9,\n",
    "#     'random_state': 0,\n",
    "# }\n",
    "# fmodel_neu = train_xgb(\n",
    "#     dfXY=df, tvt_idx=tvt_idx, cname_feats=cname_feats, cname_target='is_neu', option_init=option_init)\n",
    "\n",
    "# tvt_idx = get_tvt_idx(df)\n",
    "# cname_feats = sorted([c for c in df.columns if c not in excl_cols and not c.startswith('pred_')])\n",
    "# option_init = {\n",
    "#     'n_estimators': 1000,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'subsample': 0.9,\n",
    "#     'colsample_bytree': 0.9,\n",
    "#     'colsample_bylevel': 0.9,\n",
    "#     'random_state': 0,\n",
    "# }\n",
    "# fmodel_pos = train_xgb(\n",
    "#     dfXY=df, tvt_idx=tvt_idx, cname_feats=cname_feats, cname_target='is_pos', option_init=option_init)\n",
    "\n",
    "# df['pred_neg'] = fmodel_neg['model'].predict_proba(df[fmodel_neg['cname_feats']])[:, 1]\n",
    "# df['pred_neu'] = fmodel_neu['model'].predict_proba(df[fmodel_neu['cname_feats']])[:, 1]\n",
    "# df['pred_pos'] = fmodel_pos['model'].predict_proba(df[fmodel_pos['cname_feats']])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5cb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvt_idx = get_tvt_idx(df)\n",
    "# cname_feats = sorted([c for c in df.columns if c not in excl_cols])\n",
    "# print(cname_feats)\n",
    "# option_init = {\n",
    "#     'n_estimators': 20000,\n",
    "#     'learning_rate': 0.001,\n",
    "#     'subsample': 0.9,\n",
    "#     'colsample_bytree': 0.7,\n",
    "#     'colsample_bylevel': 0.7,\n",
    "#     'random_state': 0,\n",
    "# }\n",
    "# fmodel = train_xgb_regressor(\n",
    "#     dfXY=df, tvt_idx=tvt_idx, cname_feats=cname_feats, cname_target='label_id', option_init=option_init)\n",
    "# display(get_feature_importance_from_model(fmodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "411ff07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['reg'] = fmodel['model'].predict(df[fmodel['cname_feats']])\n",
    "# i_neg = (df['label_id']==0)\n",
    "# i_neu = (df['label_id']==1)\n",
    "# i_pos = (df['label_id']==2)\n",
    "\n",
    "# i_train = (df['tvt']=='train')\n",
    "# i_val = (df['tvt']=='val')\n",
    "# i_test = (df['tvt']=='test')\n",
    "# col = 'reg'\n",
    "# fig, ax = plt.subplots(figsize=(15, 7))\n",
    "# df[i_neg&(i_train|i_val)][col].hist(bins=100, alpha=0.5, label='Negative', density=True, ax=ax)\n",
    "# df[i_neu&(i_train|i_val)][col].hist(bins=100, alpha=0.5, label='Neutral', density=True, ax=ax)\n",
    "# df[i_pos&(i_train|i_val)][col].hist(bins=100, alpha=0.5, label='Positive', density=True, ax=ax)\n",
    "# plt.title('Histogram of Regression')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f3d1c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_XYG(pdXY, features, target, query_id):\n",
    "#     z = pdXY.sort_values(query_id)\n",
    "#     X = z[features].values\n",
    "#     Y = z[target].values\n",
    "#     G = list(pdXY.groupby(query_id).size())\n",
    "#     return X,Y,G\n",
    "\n",
    "# def compute_evaluation_metrics(model, best_ntree, x_train, y_train, x_val, y_val, x_test, y_test):\n",
    "# #     train_score = model.predict_proba(x_train, ntree_limit=best_ntree)\n",
    "#     train_pred = model.predict(x_train, ntree_limit=best_ntree)\n",
    "# #     val_score = model.predict_proba(x_val, ntree_limit=best_ntree)\n",
    "#     val_pred = model.predict(x_val, ntree_limit=best_ntree)\n",
    "# #     test_score = model.predict_proba(x_test, ntree_limit=best_ntree)\n",
    "#     test_pred = model.predict(x_test, ntree_limit=best_ntree)\n",
    "#     print(train_pred)\n",
    "#     train_auc = roc_auc_score(y_true=y_train, y_score=train_pred)\n",
    "#     train_acc = 0\n",
    "#     val_auc = roc_auc_score(y_true=y_val, y_score=train_pred, multi_class='ovo')\n",
    "#     val_acc = 0\n",
    "#     test_auc = roc_auc_score(y_true=y_test, y_score=train_pred, multi_class='ovo')\n",
    "#     test_acc = 0\n",
    "#     return train_auc, train_acc, val_auc, val_acc, test_auc, test_acc\n",
    "\n",
    "# def train_xgb_ranker(\n",
    "#     dfXY, tvt_idx, cname_feats, cname_target='label', query_id='length_group', option_init={}, option_fit={}):\n",
    "#     default_option_fit = {\n",
    "#         'eval_metric': 'auc',\n",
    "#         'verbose': False,\n",
    "#         'early_stopping_rounds': 20,\n",
    "#     }\n",
    "#     default_option_init = {\n",
    "#            'objective': 'rank:pairwise',\n",
    "# #         'max_depth': 5,\n",
    "# #         'n_estimators': 200,   \n",
    "# #         'learning_rate': 0.001,\n",
    "# #         'gamma': 0.0,\n",
    "# #         'min_child_weight': 10,\n",
    "# #         'subsample': 0.1,\n",
    "# #         'tree_method': 'hist',\n",
    "# #         'colsample_bytree': 0.5,\n",
    "# #         'colsample_bylevel': 0.5,\n",
    "# #         'reg_alpha': 0.0,\n",
    "# #         'reg_lambda': 1.0,\n",
    "#         'random_state': 0,\n",
    "#         'n_jobs': 32\n",
    "#     }\n",
    "#     default_option_fit.update(option_fit)\n",
    "#     default_option_init.update(option_init)\n",
    "#     option_fit = default_option_fit\n",
    "#     option_init = default_option_init\n",
    "    \n",
    "#     x_train, y_train, g_train = get_XYG(dfXY[tvt_idx[0][1]], cname_feats, cname_target, query_id)\n",
    "#     x_val, y_val, g_val = get_XYG(dfXY[tvt_idx[1][1]], cname_feats, cname_target, query_id)\n",
    "#     x_test, y_test, g_test = get_XYG(dfXY[tvt_idx[2][1]], cname_feats, cname_target, query_id)\n",
    "    \n",
    "#     eval_set = [\n",
    "#         (x_train, y_train),\n",
    "#         (x_val, y_val),\n",
    "#     ]\n",
    "#     eval_group = [g_train, g_val]\n",
    "    \n",
    "#     model = xgb.XGBRanker(**option_init)\n",
    "#     model.fit(x_train, y_train, g_train, eval_set=eval_set, eval_group=eval_group, **option_fit)    \n",
    "#     best_ntree = model.get_booster().best_ntree_limit  \n",
    "    \n",
    "#     train_auc, train_acc, val_auc, val_acc, test_auc, test_acc = compute_evaluation_metrics(\n",
    "#         model, best_ntree, x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "#     print('n_features n_train n_val n_test n_tree train_auc train_acc val_auc val_acc test_auc test_acc')\n",
    "#     print('{} {} {} {} {} {:.5f} {:.5f} {:.5f} {:.5f} {:.5f} {:.5f}'.format(\n",
    "#         len(cname_feats), x_train.shape[0], x_val.shape[0], x_test.shape[0], best_ntree,\n",
    "#         train_auc, train_acc, val_auc, val_acc, test_auc, test_acc))\n",
    "    \n",
    "#     # track\n",
    "#     fmodel = {\n",
    "#         'model': model,\n",
    "#         'cname_target': cname_target,\n",
    "#         'cname_feats': cname_feats,  \n",
    "#     }\n",
    "#     return fmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5480d51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmodel = train_xgb_ranker(\n",
    "#     dfXY=df, tvt_idx=tvt_idx, cname_feats=cname_feats, cname_target='label_id', option_init=option_init)\n",
    "# display(get_feature_importance_from_model(fmodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d1a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
